"""
Ù¾Ø§Ø±Ø³ HTML Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§
"""

import re
import base64
import json
from bs4 import BeautifulSoup
from typing import List, Dict

class ConfigParser:
    """Ù¾Ø§Ø±Ø³ Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² HTML"""
    
    # Ù¾ØªØ±Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯
    PATTERNS = {
        'vless': r'vless://[a-zA-Z0-9\-]+@[^:\s]+:\d+[^#\s]*(?:#[^\s]*)?',
        'vmess': r'vmess://[A-Za-z0-9+/=]+',
        'trojan': r'trojan://[a-zA-Z0-9\-]+@[^:\s]+:\d+[^#\s]*(?:#[^\s]*)?',
        'ss': r'ss://[A-Za-z0-9+/=]+@[^:\s]+:\d+(?:#[^\s]*)?',
        'mtproto': r'mtproto://[A-Za-z0-9+/=]+'
    }
    
    @staticmethod
    def parse_html(html_content: str) -> List[Dict]:
        """Ù¾Ø§Ø±Ø³ HTML Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§"""
        soup = BeautifulSoup(html_content, 'html.parser')
        configs = []
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù‡Ù…Ù‡ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
        messages = soup.find_all('div', class_='message')
        
        for msg in messages:
            text_div = msg.find('div', class_='text')
            if not text_div:
                continue
            
            text = text_div.get_text('\n', strip=True)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
            config_data = {
                'raw_text': text,
                'ping': ConfigParser.extract_ping(text),
                'location': ConfigParser.extract_location(text),
                'configs': []
            }
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§
            for proto, pattern in ConfigParser.PATTERNS.items():
                matches = re.findall(pattern, text)
                for match in matches:
                    config_info = {
                        'type': proto.upper(),
                        'link': match,
                        'remark': ConfigParser.extract_remark(match, proto)
                    }
                    config_data['configs'].append(config_info)
            
            if config_data['configs']:
                configs.append(config_data)
        
        return configs
    
    @staticmethod
    def extract_ping(text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾ÛŒÙ†Ú¯ Ø§Ø² Ù…ØªÙ†"""
        patterns = [
            r'ğŸ“¶\s*Ù¾ÛŒÙ†Ú¯[:\s]*(\d+)\s*ms',
            r'Ù¾ÛŒÙ†Ú¯[:\s]*(\d+)\s*ms',
            r'ping[:\s]*(\d+)\s*ms'
        ]
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return f"{match.group(1)}ms"
        return "---"
    
    @staticmethod
    def extract_location(text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÙˆÚ©ÛŒØ´Ù† Ø§Ø² Ù…ØªÙ†"""
        patterns = [
            r'ğŸ“\s*Ù„ÙˆÚ©ÛŒØ´Ù†[:\s]*([^\n]+)',
            r'Ù„ÙˆÚ©ÛŒØ´Ù†[:\s]*([^\n]+)',
            r'ğŸŒ\s*([^\n]+)'
        ]
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(1).strip()
        return "Unknown"
    
    @staticmethod
    def extract_remark(link: str, proto: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ú©Ø§Ù†ÙÛŒÚ¯"""
        if '#' in link:
            return link.split('#')[-1]
        
        # Ø¨Ø±Ø§ÛŒ vmess
        if proto == 'vmess':
            try:
                b64 = link.replace('vmess://', '')
                # Ù¾Ø¯ÛŒÙ†Ú¯
                padding = 4 - len(b64) % 4
                if padding != 4:
                    b64 += '=' * padding
                json_str = base64.b64decode(b64).decode('utf-8')
                data = json.loads(json_str)
                return data.get('ps', 'Unknown')
            except:
                pass
        
        return "Unknown"
